
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Model training tips &amp; tricks &#8212; DeepLabCut</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Some data processing recipes!" href="post.html" />
    <link rel="prev" title="Input/output manipulations with DeepLabCut" href="io.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">DeepLabCut</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome!
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Main Documentation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   Welcome to Our Documentation Hub!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../installation.html">
   How To Install DeepLabCut
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../standardDeepLabCut_UserGuide.html">
   DeepLabCut User Guide (for single animal projects)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../maDLC_UserGuide.html">
   DeepLabCut for Multi-Animal Projects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../PROJECT_GUI.html">
   Interactive Project Manager GUI
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Overviewof3D.html">
   3D DeepLabCut
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial.html">
   Multi-animal pose estimation with DeepLabCut: A 5-minute tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../convert_maDLC.html">
   How to convert a pre-2.2 project for use with DeepLabCut 2.2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../HelperFunctions.html">
   Helper &amp; Advanced Optional Function Documentation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Recipes
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="installTips.html">
   Installation Tips
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="io.html">
   Input/output manipulations with DeepLabCut
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Model training tips &amp; tricks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="post.html">
   Some data processing recipes!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="BatchProcessing.html">
   Automate training and video analysis: Batch Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="TechHardware.html">
   Technical (Hardware) Considerations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DLCMethods.html">
   How to write a DLC Methods Section
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Mission &amp; Contribute
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../MISSION_AND_VALUES.html">
   Mission and Values of DeepLabCut
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../roadmap.html">
   A development roadmap for DeepLabCut
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Governance.html">
   Governance Model of DeepLabCut
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/docs/recipes/nn.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/DeepLabCut/DeepLabCut"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/DeepLabCut/DeepLabCut/issues/new?title=Issue%20on%20page%20%2Fdocs/recipes/nn.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#limiting-a-gpu-s-memory-consumption">
   Limiting a GPU’s memory consumption
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-custom-image-augmentation">
   Using custom image augmentation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluating-intermediate-and-all-snapshots">
   Evaluating intermediate (and all) snapshots
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-neural-network-should-i-use-trade-offs-speed-performance-and-considerations">
   What neural network should I use? (Trade offs, speed performance, and considerations)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#with-the-release-of-even-more-network-options-you-now-have-to-decide-what-to-use-this-additionally-flexibility-is-hopefully-helpful-but-we-want-to-give-you-some-guidance-on-where-to-start">
     With the release of even more network options, you now have to decide what to use! This additionally flexibility is hopefully helpful, but we want to give you some guidance on where to start.
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resnets">
   ResNets:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#when-should-i-use-a-mobilenet">
   When should I use a MobileNet?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#when-should-i-use-an-efficientnet">
   When should I use an EfficientNet?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-can-i-compare-them">
   How can I compare them?
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="model-training-tips-tricks">
<h1>Model training tips &amp; tricks<a class="headerlink" href="#model-training-tips-tricks" title="Permalink to this headline">¶</a></h1>
<div class="section" id="limiting-a-gpu-s-memory-consumption">
<h2>Limiting a GPU’s memory consumption<a class="headerlink" href="#limiting-a-gpu-s-memory-consumption" title="Permalink to this headline">¶</a></h2>
<p>All GPU memory is allocated to training by default, preventing
other Tensorflow processes from being run on the same machine.</p>
<p>A flexible solution to limiting memory usage is to call <code class="docutils literal notranslate"><span class="pre">deeplabcut.train(...,</span> <span class="pre">allow_growth=True)</span></code>,
which dynamically grows the GPU memory region as it is needed.
Another, stricter option is to explicitly cap GPU usage to only a fraction
of the available memory. For example, allocating a maximum of 1/4 of the total
memory could be done as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">gpu_options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">GPUOptions</span><span class="p">(</span><span class="n">per_process_gpu_memory_fraction</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">(</span><span class="n">gpu_options</span><span class="o">=</span><span class="n">gpu_options</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="using-custom-image-augmentation">
<h2>Using custom image augmentation<a class="headerlink" href="#using-custom-image-augmentation" title="Permalink to this headline">¶</a></h2>
<p>Image augmentation is the process of artificially expanding the training set
by applying various transformations to images (e.g., rotation or rescaling)
in order to make models more robust and more accurate (read our
<a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0896627320307170">primer</a> for
more information). Although data augmentation is automatically accomplished
by DeepLabCut, default values (see the augmentation variables in the
<a class="reference external" href="https://github.com/DeepLabCut/DeepLabCut/blob/master/deeplabcut/pose_cfg.yaml#L23-L74">default pose_cfg.yaml</a> file)
can be readily overwritten prior to training.</p>
<p>When you <code class="docutils literal notranslate"><span class="pre">create_training_dataset</span></code> <a class="reference external" href="https://github.com/AlexEMG/DeepLabCut/blob/master/docs/UseOverviewGuide.md#create-training-dataset">you have several options</a> on what types of augmentation to use.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">deeplabcut</span><span class="o">.</span><span class="n">create_training_dataset</span><span class="p">(</span><span class="n">configpath</span><span class="p">,</span> <span class="n">augmenter_type</span><span class="o">=</span><span class="s1">&#39;imgaug&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>When you do this (i.e. pass <code class="docutils literal notranslate"><span class="pre">augmenter_type</span></code>) what underlying files you are calling are these:
<a class="reference external" href="https://github.com/DeepLabCut/DeepLabCut/tree/master/deeplabcut/pose_estimation_tensorflow/datasets">https://github.com/DeepLabCut/DeepLabCut/tree/master/deeplabcut/pose_estimation_tensorflow/datasets</a>
You can look at what types of augmentation are available to you (or edit those files to add more). Moreover, you can add more options to the pose_cfg.yaml file. Here is a simple script you can modify and run to automatically edit the correct pose_cfg.yaml to add more augmentation to the <code class="docutils literal notranslate"><span class="pre">imgaug</span></code> loader (or open it and edit yourself).</p>
<p>But, you can add more:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">deeplabcut</span>

<span class="n">train_pose_config</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">deeplabcut</span><span class="o">.</span><span class="n">return_train_network_path</span><span class="p">(</span><span class="n">config_path</span><span class="p">)</span>
<span class="n">augs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;gaussian_noise&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s2">&quot;elastic_transform&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s2">&quot;rotation&quot;</span><span class="p">:</span> <span class="mi">180</span><span class="p">,</span>
    <span class="s2">&quot;covering&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s2">&quot;motion_blur&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">deeplabcut</span><span class="o">.</span><span class="n">auxiliaryfunctions</span><span class="o">.</span><span class="n">edit_config</span><span class="p">(</span>
    <span class="n">train_pose_config</span><span class="p">,</span>
    <span class="n">augs</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="evaluating-intermediate-and-all-snapshots">
<h2>Evaluating intermediate (and all) snapshots<a class="headerlink" href="#evaluating-intermediate-and-all-snapshots" title="Permalink to this headline">¶</a></h2>
<p>The latest snapshot stored during training may not necessarily be the one that yields the highest performance. Therefore, you should analyze ALL snapshots, and select the best. Put ‘all’ in the snapshots section of the config.yaml to do this.</p>
</div>
<div class="section" id="what-neural-network-should-i-use-trade-offs-speed-performance-and-considerations">
<h2>What neural network should I use? (Trade offs, speed performance, and considerations)<a class="headerlink" href="#what-neural-network-should-i-use-trade-offs-speed-performance-and-considerations" title="Permalink to this headline">¶</a></h2>
<div class="section" id="with-the-release-of-even-more-network-options-you-now-have-to-decide-what-to-use-this-additionally-flexibility-is-hopefully-helpful-but-we-want-to-give-you-some-guidance-on-where-to-start">
<h3>With the release of even more network options, you now have to decide what to use! This additionally flexibility is hopefully helpful, but we want to give you some guidance on where to start.<a class="headerlink" href="#with-the-release-of-even-more-network-options-you-now-have-to-decide-what-to-use-this-additionally-flexibility-is-hopefully-helpful-but-we-want-to-give-you-some-guidance-on-where-to-start" title="Permalink to this headline">¶</a></h3>
<p><strong>TL;DR - your best performance for most everything is ResNet-50; MobileNetV2-1 is much faster, needs less memory on your GPU to train and nearly as accurate.</strong></p>
<p>You always select the network type when you create a training data set: i.e., standard dlc: <code class="docutils literal notranslate"><span class="pre">deeplabcut.create_training_dataset(config,</span> <span class="pre">net_type=resnet_50)</span></code> , or maDLC: <code class="docutils literal notranslate"><span class="pre">deeplabcut.create_multianimaltraining_dataset(config,</span> <span class="pre">net_type=dlcrnet_ms5)</span></code>. There is nothing else you should change.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="resnets">
<h2>ResNets:<a class="headerlink" href="#resnets" title="Permalink to this headline">¶</a></h2>
<p>In Mathis et al. 2018 we benchmarked three networks: <strong>ResNet-50, ResNet-101, and ResNet-101ws</strong>. For ALL lab applications, ResNet-50 was enough. For all the demo videos on <a class="reference external" href="http://www.mousemotorlab.org/deeplabcut">www.deeplabcut.org</a> the backbones are ResNet-50’s. Thus, we recommend making this your go-to workhorse for data analysis. Here is a figure from the paper, see panel “B” (they are all within a few pixels of eachother on the open-field dataset):</p>
<p align="center">
<img src="https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1548558406678-S32H6T3M3U7BWVS4IGYD/ke17ZwdGBToddI8pDm48kD4CqqHoJgLzZVYacqX5G8QUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dqTB9h4P9po3-YSCqzKkit0PccqviqYX7RTAdOBUgXwbCjLISwBs8eEdxAxTptZAUg/SupplFig2-01.png?format=1000w" width="80%">
</p>
<p>This is also one of the main result figures, generated with ResNet-50. BLUE is training - RED is testing - BLACK is our best human-level performance, and 10 pixels is the width of the mouse nose -so anything under that is good performance for us on this task!</p>
<p align="center">
<img src="https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1547585317499-0QWTWL5KVPK8ZWINQ30U/ke17ZwdGBToddI8pDm48kH23KVWagbNOYpajbj_MQLNZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PI-4DGGLi3WdhIPQDa6khDzRWGU5SknjCO3Yd6rloU2Zw/ErrorvsTrainingsetSize.png?format=1000w" width="60%">
</p>
<p>Here are also some speed stats for analyzing videos with ResNet-50, see <a class="reference external" href="https://www.biorxiv.org/content/early/2018/10/30/457242">https://www.biorxiv.org/content/early/2018/10/30/457242</a> for more details:</p>
<p align="center">
<img src="https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1547585393723-8BQ6RGSPUUEQ1NNGUQDZ/ke17ZwdGBToddI8pDm48kCebzxgICDi_Bmgq_409OyxZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PICdDqlshOygx3FUsifuoze123Z0BWMsGmyODBJYiFvQc/inferencespeed.png?format=1000w" width="60%">
</p>
<p><strong>So, why use a ResNet-101 or even 152?</strong> if you have a much more challenging problem, like multiple humans dancing, this is a good option. You should then also set <code class="docutils literal notranslate"><span class="pre">intermediate_supervision=True</span></code> for best performance in the pose_config.yaml of that shuffle folder ( before you train). Note, for ResNet-50 this does NOT help, and can hurt.</p>
</div>
<div class="section" id="when-should-i-use-a-mobilenet">
<h2>When should I use a MobileNet?<a class="headerlink" href="#when-should-i-use-a-mobilenet" title="Permalink to this headline">¶</a></h2>
<p>MobileNets are fast to run, fast to train, more memory efficient, and faster for analysis (inference) - e.g. on CPUs they are 4 times faster, on GPUs up to 2x! So, if you don’t have a GPU (or a GPU with little memory), and don’t want to use Google COLAB, etc, then these are a great starting point.</p>
<p>They are smaller/shallower networks though, so you don’t want to be pushing in very large images. So, be sure to use <code class="docutils literal notranslate"><span class="pre">deeplabcut.DownSampleVideo</span></code> on your data (which is frankly never a bad idea).</p>
<p>Additionally, these are good options for running on “live” videos, i.e. if you want to give real-time feedback in an experiment, you can run a video around a smaller cropped area, and run this rather fast!</p>
<p><strong>So, how fast are they?</strong></p>
<p>Here are comparisons of 4 MobileNetV2 variants to ResNet-50 and ResNet-101 (darkest red):
read more here: <a class="reference external" href="https://arxiv.org/abs/1909.11229">https://arxiv.org/abs/1909.11229</a></p>
<p align="center">
<img src="https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1570054128042-51HCY1Y9GV7GAQTZ5BMB/ke17ZwdGBToddI8pDm48kKr5oWkDv6XTQOpQfQOqjiAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKchrM-h1v5jGhVgANO1xgMJaHKhYxZ0-Cf0LQLHXkOaBUlIOyXFtu3PNQa47ngsqiu/mbnetv2speed.png?format=1000w" width="100%">
</p>
<p align="center">
<img src="https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1570054117297-YA8WOYG50EK55WM6Y8ZI/ke17ZwdGBToddI8pDm48kAWg0301pwdoqO-Bo48aILYUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcZbh5EzlyubXk7Q3qHw5ayJHISnXwMOq8Pp90__8eMJefaZFcnumpU7B4DHTHEFkQ/speedtables.png?format=1000w" width="100%">
</p>
</div>
<div class="section" id="when-should-i-use-an-efficientnet">
<h2>When should I use an EfficientNet?<a class="headerlink" href="#when-should-i-use-an-efficientnet" title="Permalink to this headline">¶</a></h2>
<p>Built with inverse residual blocks like MobileNets, but more powerful than ResNets, due to optimal depth/width/resolution scaling, <a class="reference external" href="https://arxiv.org/abs/1905.11946">EfficientNet</a> are an excellent choice if you want speed and performance. They do require more careful handling though! Especially for small datasets, you will need to tune the batch size and learning rates. So, we suggest these for more advanced users, or those willing to run experiments to find the best settings. Here is the speed comparison, and for performance see our latest work at: <a class="reference external" href="http://horse10.deeplabcut.org">http://horse10.deeplabcut.org</a></p>
<p align="center">
<img src="https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1615891029784-87JAZJN1C5S4HS62F752/ke17ZwdGBToddI8pDm48kLId9V2zDiOqQ5EIZz4b_S0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctCpCjeabgTq1Hv_G9BIks_zjAnmEpAaVGioFPvsrieXDegXGHA0z-h8QeHOQDokM/speedTest.png?format=1000w" width="100%">
</p>
</div>
<div class="section" id="how-can-i-compare-them">
<h2>How can I compare them?<a class="headerlink" href="#how-can-i-compare-them" title="Permalink to this headline">¶</a></h2>
<p>Great question! So, the best way to do this is to use the <strong>same</strong> test/train split (that is generated in create_training_dataset) with different models. Here, as of 2.1+, we have a <strong>new</strong> function that lets you do this easily. Instead of using <code class="docutils literal notranslate"><span class="pre">create_training_dataset</span></code> you will run <code class="docutils literal notranslate"><span class="pre">create_training_model_comparison</span></code> (see the docstrings by <code class="docutils literal notranslate"><span class="pre">deeplabcut.create_training_model_comparison?</span></code> or run the Project Manager GUI - <code class="docutils literal notranslate"><span class="pre">deeplabcut.launch_dlc()</span></code>-  for assistance.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs/recipes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="io.html" title="previous page">Input/output manipulations with DeepLabCut</a>
    <a class='right-next' id="next-link" href="post.html" title="next page">Some data processing recipes!</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By The DeepLabCut Team<br/>
        
            &copy; Copyright 2021.<br/>
          <div class="extra_footer">
            <div>Powered by <a href="https://jupyterbook.org/">Jupyter Book</a>.</div>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>